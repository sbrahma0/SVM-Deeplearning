{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "batch_size = 100\n",
    "data_augmentation = False\n",
    "img_size = 28\n",
    "\n",
    "num_classes = 10\n",
    "num_filters = 128\n",
    "num_blocks = 4\n",
    "num_sub_blocks = 2\n",
    "use_max_pool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n",
      "(10000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 128)  6400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 128)  147584      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 128)  147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 128)  0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 128)  147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 14, 14, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 14, 14, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 128)  147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 128)  0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 14, 14, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 256)    295168      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 256)    590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 256)    33024       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 256)    1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 256)    0           conv2d_8[0][0]                   \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 256)    590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 256)    1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 7, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 7, 7, 256)    0           activation_7[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 512)    1180160     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 512)    2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 512)    131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 512)    0           conv2d_13[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 512)    2359808     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 512)    2359808     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 512)    2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 1024)   4719616     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2, 2, 1024)   4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 1024)   9438208     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 1024)   525312      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 2, 1024)   4096        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 1024)   0           conv2d_18[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 1024)   9438208     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2, 2, 1024)   4096        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 1024)   9438208     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 2, 2, 1024)   4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 1024)   0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 1024)   0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,687,370\n",
      "Trainable params: 44,671,754\n",
      "Non-trainable params: 15,616\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (img_size, img_size,1)\n",
    "#Creating model based on ResNet published archietecture\n",
    "inputs = Input(shape=input_size)\n",
    "x = Conv2D(num_filters, padding='same', \n",
    "           kernel_initializer='he_normal', \n",
    "           kernel_size=7, strides=2,\n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#Check by applying max pooling later (setting it false as size of image is small i.e. 28x28)\n",
    "if use_max_pool:\n",
    "    x = MaxPooling2D(pool_size=3,padding='same', strides=2)(x)\n",
    "    num_blocks =3\n",
    "#Creating Conv base stack \n",
    "\n",
    "# Instantiate convolutional base (stack of blocks).\n",
    "for i in range(num_blocks):\n",
    "    for j in range(num_sub_blocks):\n",
    "        strides = 1\n",
    "        is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            strides = 2\n",
    "        #Creating residual mapping using y\n",
    "        y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   strides=strides,\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            x = Conv2D(num_filters,\n",
    "                       kernel_size=1,\n",
    "                       padding='same',\n",
    "                       strides=2,\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(x)\n",
    "        #Adding back residual mapping\n",
    "        x = keras.layers.add([x, y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    num_filters = 2 * num_filters\n",
    "\n",
    "# Add classifier on top.\n",
    "x = AveragePooling2D()(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(num_classes,\n",
    "                activation='softmax',\n",
    "                kernel_initializer='he_normal')(y)\n",
    "\n",
    "# Instantiate and compile model.\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_model')\n",
    "model_name = 'fmnist_resnet_model.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir,model_name)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare callbacks for model saving and for learning rate decaying.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.np_utils.to_categorical(y_test)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 1.8573 - accuracy: 0.8498 - val_loss: 1.2564 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25637, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.9809 - accuracy: 0.8957 - val_loss: 0.8139 - val_accuracy: 0.8926\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.25637 to 0.81393, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.6823 - accuracy: 0.9098 - val_loss: 0.6400 - val_accuracy: 0.8989\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81393 to 0.64002, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.5674 - accuracy: 0.9118 - val_loss: 0.6076 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64002 to 0.60762, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 137s 2ms/step - loss: 0.5321 - accuracy: 0.9161 - val_loss: 0.5692 - val_accuracy: 0.9045\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60762 to 0.56916, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 146s 2ms/step - loss: 0.4929 - accuracy: 0.9188 - val_loss: 0.5100 - val_accuracy: 0.9027\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56916 to 0.50998, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 153s 3ms/step - loss: 0.4812 - accuracy: 0.9216 - val_loss: 0.5522 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.50998\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.4095 - accuracy: 0.9287 - val_loss: 0.4658 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.50998 to 0.46584, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.5153 - accuracy: 0.9229 - val_loss: 0.4709 - val_accuracy: 0.9098\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46584\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.4092 - accuracy: 0.9337 - val_loss: 0.4590 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.46584 to 0.45902, saving model to E:\\MD\\3rd semester\\SPR\\project\\fashion-mnist-master\\fashion-mnist-master\\saved_model\\fmnist_resnet_model.h5\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.4393 - accuracy: 0.9322 - val_loss: 1.5644 - val_accuracy: 0.7745\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.4985 - accuracy: 0.9349 - val_loss: 0.4901 - val_accuracy: 0.9136\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45902\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Test loss: 0.49007431011199953\n",
      "Test accuracy: 0.9136000275611877\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With 12 epoch it gace 91.3% accuracy, with 100 it gave close to 92% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
